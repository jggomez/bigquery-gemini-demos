# -*- coding: utf-8 -*-
"""gemini-exercise-data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/devhack-3f0c2/locations/us-central1/repositories/df32fe82-2bf1-4400-80a4-1c8b94b95879

# Definir variables e inicializar Bigquery y vertexAI
"""

from google.cloud import bigquery
from google.cloud import aiplatform
import bigframes.pandas as bpd
import pandas as pd
from vertexai.language_models._language_models import TextGenerationModel
from vertexai.generative_models import GenerativeModel
from bigframes.ml.cluster import KMeans
from bigframes.ml.model_selection import train_test_split

project_id = 'devhack-3f0c2'
dataset_name = "ecommerce"
model_name = "customer_segmentation_model"
table_name = "customer_stats"
location = "us-central1"
client = bigquery.Client(project=project_id)
aiplatform.init(project=project_id, location=location)

"""### **Crear tabla de las estadisticas del cliente e importarlos del dataset publico**"""

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# CREATE OR REPLACE TABLE ecommerce.customer_stats AS
# SELECT
#   user_id,
#   DATE_DIFF(CURRENT_DATE(), CAST(MAX(order_created_date) AS DATE), day) AS days_since_last_order, ---RECENCY
#   COUNT(order_id) AS count_orders, --FREQUENCY
#   AVG(sale_price) AS average_spend --MONETARY
#   FROM (
#       SELECT
#         user_id,
#         order_id,
#         sale_price,
#         created_at AS order_created_date
#         FROM `bigquery-public-data.thelook_ecommerce.order_items`
#         WHERE
#         created_at
#             BETWEEN '2022-01-01' AND '2023-01-01'
#   )
# GROUP BY user_id;

"""### **Crear BigFrame**"""

bqdf = bpd.read_gbq(f"{project_id}.{dataset_name}.{table_name}")
bqdf.head()
bqdf.tail()

bqdf[bqdf["user_id"] == 8172]

"""### **K-Means Clustering Model**

1. Split df (using random state and test size 0.2) into test and training data for a K-means clustering algorithm store these as df_test and df_train. 2. Create a K-means cluster model using bigframes.ml.cluster KMeans with 5 clusters. 3. Save the model using the to_gbq method where the model name is project_id.dataset_name.model_name.
"""

# prompt: 1. Split df (using random state and test size 0.2) into test and training data for a K-means clustering algorithm store these as df_test and df_train. 2. Create a K-means cluster model using bigframes.ml.cluster KMeans with 5 clusters. 3. Save the model using the to_gbq method where the model name is project_id.dataset_name.model_name.

df_train, df_test = train_test_split(bqdf, test_size=0.2, random_state=42)
kmeans = KMeans(n_clusters=5)
kmeans.fit(df_train)
kmeans.to_gbq(model_name=f"{project_id}.{dataset_name}.{model_name}")

predictions_df = kmeans.predict(df_test)
predictions_df.head(10)

"""### **Visualizar el k-means Clustering**"""

# prompt: visualizar el clustering creado

import matplotlib.pyplot as plt

# Assuming 'predictions_df' contains the cluster labels and features for plotting
# Replace 'feature1' and 'feature2' with the actual column names from your DataFrame

plt.figure(figsize=(10, 6))
plt.scatter(predictions_df['days_since_last_order'], predictions_df['average_spend'], c=predictions_df['CENTROID_ID'], cmap='viridis')
plt.xlabel('days_since_last_order')
plt.ylabel('average_spend')
plt.title('K-means Clustering Visualization')
plt.colorbar(label="Cluster ID")
plt.show()

"""### **Resumen por cada cluster**"""

query = """
SELECT
 CONCAT('cluster ', CAST(centroid_id as STRING)) as centroid,
 average_spend,
 count_orders,
 days_since_last_order
FROM (
 SELECT centroid_id, feature, ROUND(numerical_value, 2) as value
 FROM ML.CENTROIDS(MODEL `{0}.{1}`)
)
PIVOT (
 SUM(value)
 FOR feature IN ('average_spend',  'count_orders', 'days_since_last_order')
)
ORDER BY centroid_id
""".format(dataset_name, model_name)

df_centroid = client.query(query).to_dataframe()
df_centroid.head()

df_query = client.query(query).to_dataframe()
df_query.to_string(header=False, index=False)

cluster_info = []
for i, row in df_query.iterrows():
 cluster_info.append("{0}, average spend ${2}, count of orders per person {1}, days since last order {3}"
  .format(row["centroid"], row["count_orders"], row["average_spend"], row["days_since_last_order"]) )

cluster_info = (str.join("\n", cluster_info))
print(cluster_info)

"""### **Generar campa√±a de marketing con Gemini**"""

model = GenerativeModel("gemini-2.0-flash")

prompt = f"""
You're a creative brand strategist, given the following clusters, come up with \
creative brand persona, a catchy title, and next marketing action, \
explained step by step. Identify the cluster number, the title of the person, a persona for them and the next marketing step.

Clusters:
{cluster_info}

For each Cluster:
* Title:
* Persona:
* Next marketing step:
"""

responses = model.generate_content(
   prompt,
   generation_config={
      "temperature": 0.1,
      "top_p": 1.0,
      "top_k": 40,
   }
)

print(responses.text)